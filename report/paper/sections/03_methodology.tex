\section{Methodology}
\label{sec:methodology}
I keep the pipeline minimal but reproducible. My train and validation sets are limited to subsamples of 8{,}192 slices and 1{,}024 slices respectively. Equispaced masks at $R=6$ with 20 ACS lines are applied, and training is performed with a batch size of 2 for 12 epochs, resulting in roughly 50k update steps, mirroing the number of steps reported by \cite{cole2020analysisdeepcomplexvaluedconvolutional}. Widths for the complex U-Net are $[16,32,64,128,256]$; the real U-Net uses the same widths scaled by $1.42\times$ to match the parameter count (about 12.6M parameters per model).
\subsection{Dataset and Preprocessing}
The experiments use the fastMRI single-coil knee dataset by \cite{zbontar2019fastmriopendatasetbenchmarks}. Each slice is masked with an equispaced pattern at $R=6$ and 20 ACS lines, inverse FFTs produce zero-filled inputs, and ground-truth targets are center-cropped to $640\times320$. Both masked inputs and targets are normalized by the per-slice maximum magnitude. No data augmentation is applied.
\subsection{Model Architectures}
Both models follow the U-Net macro-architecture from \citet{cole2020analysisdeepcomplexvaluedconvolutional}. The complex U-Net uses CReLU activations, complex batch normalization, and component-wise pooling; the real U-Net uses standard convolutions and ReLU. Feature widths are matched in parameter count by scaling the real channels by $1.42$, yielding roughly 12.6M parameters per model. Skip connections and bottlenecks mirror each other so differences stem only from complex versus real arithmetic.
\subsection{Training and Evaluation Protocol}
I train with Adam (learning rate $1\times10^{-3}$, betas $(0.9, 0.999)$, same as \cite{cole2020analysisdeepcomplexvaluedconvolutional}) for 12 epochs with a batch size of 2 (about 50k steps). The loss is $\ell_1$ between reconstructed and ground-truth complex images. After each epoch I log validation PSNR/SSIM/$\ell_1$ (Table~\ref{tab:main_results}) and save latest/best checkpoints; qualitative slices for three validation images are presented in Figure~\ref{fig:qualitative}. Per-epoch losses support the training-curve plot in Figure~\ref{fig:training_curve}.
