{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Runner â€” Automated Batch\n",
    "Runs zero-filled and real/complex U-Nets sequentially so overnight jobs log everything needed for the paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. Configure experiments in the cell below.\n",
    "2. Execute the final cell to iterate through each run.\n",
    "3. Inspect `results/` in the morning for metrics, checkpoints, and figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b630d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == 'notebooks':\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "SRC_ROOT = PROJECT_ROOT / 'src'\n",
    "RESULTS_ROOT = PROJECT_ROOT / 'results'\n",
    "RESULTS_ROOT.mkdir(exist_ok=True)\n",
    "import sys\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "from data.dataset import SingleCoilDataset\n",
    "from data.masking import EquispacedMasker\n",
    "from models.real_unet import RealUnet\n",
    "from models.cx_unet import ComplexUnet\n",
    "from training.utils import train_loop, test_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d595f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_EVERY = 1\n",
    "\n",
    "\n",
    "def init_run(run_tag: str, config: dict) -> Path:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    # run_dir = RESULTS_ROOT / f\"{timestamp}_{run_tag}\"\n",
    "    run_dir = RESULTS_ROOT / run_tag\n",
    "    (run_dir / 'checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / 'qualitative').mkdir(exist_ok=True)\n",
    "    (run_dir / 'metrics').mkdir(exist_ok=True)\n",
    "    (run_dir / 'images').mkdir(exist_ok=True)\n",
    "    (run_dir / 'tensors').mkdir(exist_ok=True)\n",
    "    with open(run_dir / 'config.yaml', 'w') as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "    with open(run_dir / 'config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def to_mag(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.abs()\n",
    "\n",
    "\n",
    "def psnr_db(x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    mse = torch.mean((x - y) ** 2)\n",
    "    return 10.0 * torch.log10(1.0 / (mse + eps))\n",
    "\n",
    "\n",
    "def ssim_simple(x: torch.Tensor, y: torch.Tensor, C1: float = 0.01**2, C2: float = 0.03**2) -> torch.Tensor:\n",
    "    mu_x, mu_y = x.mean(), y.mean()\n",
    "    sigma_x = ((x - mu_x) ** 2).mean()\n",
    "    sigma_y = ((y - mu_y) ** 2).mean()\n",
    "    sigma_xy = ((x - mu_x) * (y - mu_y)).mean()\n",
    "    num = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    den = (mu_x**2 + mu_y**2 + C1) * (sigma_x + sigma_y + C2)\n",
    "    return num / (den + 1e-8)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_metrics(model, dataloader, device, num_batches: int | None = None):\n",
    "    model.eval()\n",
    "    psnrs, ssim_scores, l1s = [], [], []\n",
    "    for batch_idx, (masked, target) in enumerate(dataloader):\n",
    "        masked = masked.to(device)\n",
    "        target = target.to(device)\n",
    "        recon = model(masked)\n",
    "        gt = to_mag(target)\n",
    "        pred = to_mag(recon)\n",
    "        gt = gt / gt.max().clamp_min(1e-8)\n",
    "        pred = pred / pred.max().clamp_min(1e-8)\n",
    "        psnrs.append(psnr_db(pred, gt).item())\n",
    "        ssim_scores.append(ssim_simple(pred, gt).item())\n",
    "        l1s.append(torch.mean(torch.abs(pred - gt)).item())\n",
    "        if num_batches is not None and (batch_idx + 1) >= num_batches:\n",
    "            break\n",
    "    return {\n",
    "        'psnr': float(sum(psnrs) / max(len(psnrs), 1)),\n",
    "        'ssim': float(sum(ssim_scores) / max(len(ssim_scores), 1)),\n",
    "        'l1': float(sum(l1s) / max(len(l1s), 1)),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_qualitative(run_dir: Path, model, dataset, device, epoch: int, sample_idx: int | None = None):\n",
    "    model.eval()\n",
    "    if len(dataset) == 0:\n",
    "        return\n",
    "    idx = sample_idx if sample_idx is not None else (epoch * 11) % len(dataset)\n",
    "    masked, target = dataset[idx]\n",
    "    masked = masked.unsqueeze(0).to(device)\n",
    "    target = target.unsqueeze(0).to(device)\n",
    "    recon = model(masked)\n",
    "    gt = to_mag(target[0]).cpu()\n",
    "    pred = to_mag(recon[0]).detach().cpu()\n",
    "    zf = to_mag(masked[0]).cpu()\n",
    "    for img in (gt, pred, zf):\n",
    "        img /= img.max().clamp_min(1e-8)\n",
    "    plt.imsave(run_dir / 'qualitative' / f'epoch{epoch:03d}_zf.png', zf.squeeze(), cmap='gray')\n",
    "    plt.imsave(run_dir / 'qualitative' / f'epoch{epoch:03d}_pred.png', pred.squeeze(), cmap='gray')\n",
    "    plt.imsave(run_dir / 'qualitative' / f'epoch{epoch:03d}_gt.png', gt.squeeze(), cmap='gray')\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    for ax, img, title in zip(axes, [zf, pred, gt], ['Zero-filled', 'Model', 'Ground Truth']):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f'Epoch {epoch}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(run_dir / 'qualitative' / f'epoch{epoch:03d}.png', dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def select_indices(n_total: int, n_pick: int) -> np.ndarray:\n",
    "    n = min(n_total, n_pick)\n",
    "    if n_total == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    return np.linspace(0, n_total - 1, num=n, dtype=int)\n",
    "\n",
    "\n",
    "def save_zero_fill_outputs(cfg: dict, run_dir: Path):\n",
    "    accels = cfg['mask_grid']['accels']\n",
    "    acs_list = cfg['mask_grid']['acs']\n",
    "    idx = cfg.get('grid_index', 0)\n",
    "    rows = []\n",
    "    for accel in accels:\n",
    "        for acs in acs_list:\n",
    "            ds = SingleCoilDataset(cfg['val_folder'], mask_func=EquispacedMasker(accel=accel, acs=acs))\n",
    "            slice_idx = min(idx, len(ds) - 1)\n",
    "            masked, target = ds[slice_idx]\n",
    "            gt = to_mag(target).float()\n",
    "            zf = to_mag(masked).float()\n",
    "            gt = gt / gt.max().clamp_min(1e-8)\n",
    "            zf = zf / zf.max().clamp_min(1e-8)\n",
    "            psnr = psnr_db(zf, gt).item()\n",
    "            ssim = ssim_simple(zf, gt).item()\n",
    "            l1 = torch.mean(torch.abs(zf - gt)).item()\n",
    "            rows.append({'accel': accel, 'acs': acs, 'idx': int(slice_idx), 'psnr': psnr, 'ssim': ssim, 'l1': l1})\n",
    "            base = run_dir / 'images' / f'idx{slice_idx:04d}_R{accel}_ACS{acs}'\n",
    "            plt.imsave(str(base) + '_zf.png', zf.squeeze(), cmap='gray')\n",
    "            plt.imsave(str(base) + '_gt.png', gt.squeeze(), cmap='gray')\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(run_dir / 'zero_fill_metrics.csv', index=False)\n",
    "    (run_dir / 'zero_fill_metrics.json').write_text(json.dumps(rows, indent=2))\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def build_subset(dataset, subset_size):\n",
    "    if subset_size is None:\n",
    "        return dataset\n",
    "    n = min(len(dataset), subset_size)\n",
    "    indices = list(range(n))\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "def train_epoch_with_logs(model, dataloader, optimizer, loss_fn, device, epoch: int, global_step: int, log_every: int = 100):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    step_logs = []\n",
    "    progress = tqdm(dataloader, desc=f\"train epoch {epoch}\", leave=False)\n",
    "    for step, (images_masked, images_full) in enumerate(progress, start=1):\n",
    "        images_masked = images_masked.to(device)\n",
    "        images_full = images_full.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images_masked)\n",
    "        loss = loss_fn(outputs, images_full)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        global_step += 1\n",
    "        if global_step % log_every == 0:\n",
    "            step_logs.append({'global_step': global_step, 'epoch': epoch, 'step': step, 'loss': loss.item()})\n",
    "    avg_loss = total_loss / max(len(dataloader), 1)\n",
    "    return avg_loss, global_step, step_logs\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    progress = tqdm(dataloader, desc=\"val\", leave=False)\n",
    "    for images_masked, images_full in progress:\n",
    "        images_masked = images_masked.to(device)\n",
    "        images_full = images_full.to(device)\n",
    "        outputs = model(images_masked)\n",
    "        loss = loss_fn(outputs, images_full)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(len(dataloader), 1)\n",
    "\n",
    "\n",
    "def run_zero_fill_experiment(cfg: dict):\n",
    "    run_dir = init_run(cfg['run_tag'], cfg)\n",
    "    save_zero_fill_outputs(cfg, run_dir)\n",
    "\n",
    "\n",
    "def run_model_experiment(cfg: dict):\n",
    "    torch.manual_seed(cfg.get('seed', 0))\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    run_dir = init_run(cfg['run_tag'], cfg)\n",
    "    mask_cfg = cfg.get('mask', {'accel': 4, 'acs': 24})\n",
    "    masker = EquispacedMasker(accel=mask_cfg['accel'], acs=mask_cfg['acs'])\n",
    "    train_full = SingleCoilDataset(cfg['train_folder'], mask_func=masker)\n",
    "    val_full = SingleCoilDataset(cfg['val_folder'], mask_func=masker)\n",
    "    train_set = build_subset(train_full, cfg.get('train_subset'))\n",
    "    val_set = build_subset(val_full, cfg.get('val_subset'))\n",
    "    train_loader = DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'])\n",
    "    val_loader = DataLoader(val_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'])\n",
    "    features = cfg.get('features', [32, 64, 128, 256, 512])\n",
    "    if cfg.get('model', 'real') == 'complex':\n",
    "        model = ComplexUnet(in_channels=1, out_channels=1, features=features).to(device)\n",
    "    else:\n",
    "        model = RealUnet(in_channels=1, out_channels=1, features=features, width_scale=cfg.get('width_scale', 1.0)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "    loss_fn = lambda pred, target: (pred - target).abs().mean()\n",
    "\n",
    "    step_path = run_dir / 'metrics' / 'step_metrics.csv'\n",
    "    epoch_path = run_dir / 'metrics' / 'epoch_metrics.csv'\n",
    "    with step_path.open('w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['global_step', 'epoch', 'step', 'loss'])\n",
    "        writer.writeheader()\n",
    "    with epoch_path.open('w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['epoch', 'train_loss', 'val_loss', 'psnr', 'ssim', 'l1'])\n",
    "        writer.writeheader()\n",
    "    summary_path = run_dir / 'metrics' / 'summary.json'\n",
    "\n",
    "    best_val = float('inf')\n",
    "    best_epoch = 0\n",
    "    global_step = 0\n",
    "    qual_idx = cfg.get('qualitative_index', 0)\n",
    "\n",
    "    for epoch in range(1, cfg['epochs'] + 1):\n",
    "        train_loss, global_step, step_logs = train_epoch_with_logs(model, train_loader, optimizer, loss_fn, device, epoch, global_step, log_every=LOG_EVERY)\n",
    "        if step_logs:\n",
    "            with step_path.open('a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=['global_step', 'epoch', 'step', 'loss'])\n",
    "                writer.writerows(step_logs)\n",
    "        val_loss = validate_epoch(model, val_loader, loss_fn, device)\n",
    "        metrics = evaluate_metrics(model, val_loader, device, num_batches=None)\n",
    "        with epoch_path.open('a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['epoch', 'train_loss', 'val_loss', 'psnr', 'ssim', 'l1'])\n",
    "            writer.writerow({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, **metrics})\n",
    "        summary = {\n",
    "            'best_val_loss': float(min(best_val, val_loss)),\n",
    "            'best_epoch': int(best_epoch if val_loss >= best_val else epoch),\n",
    "            'last_epoch': int(epoch),\n",
    "            'device': str(device),\n",
    "            'global_step': int(global_step),\n",
    "        }\n",
    "        summary_path.write_text(json.dumps(summary, indent=2))\n",
    "        torch.save({'model': model.state_dict(), 'epoch': epoch}, run_dir / 'checkpoints' / 'latest.pt')\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save({'model': model.state_dict(), 'epoch': epoch}, run_dir / 'checkpoints' / 'best.pt')\n",
    "        save_qualitative(run_dir, model, val_set, device, epoch, sample_idx=qual_idx)\n",
    "        print(f\"[{cfg['run_tag']}] Epoch {epoch}/{cfg['epochs']} | train {train_loss:.4f} | val {val_loss:.4f} | psnr {metrics['psnr']:.2f} | ssim {metrics['ssim']:.3f} | l1 {metrics['l1']:.4f}\")\n",
    "\n",
    "\n",
    "def run_experiment(cfg: dict):\n",
    "    exp_type = cfg['type']\n",
    "    print(f\"=== Running {cfg['run_tag']} ({exp_type}) ===\")\n",
    "    if exp_type == 'zero_fill':\n",
    "        run_zero_fill_experiment(cfg)\n",
    "    elif exp_type == 'model':\n",
    "        run_model_experiment(cfg)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown experiment type: {exp_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b194566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'run_tag': 'zerofill_quick',\n",
       "  'type': 'zero_fill',\n",
       "  'val_folder': '/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/data/singlecoil_val',\n",
       "  'val_subset': 4,\n",
       "  'grid_index': 0,\n",
       "  'mask_grid': {'accels': [6], 'acs': [20]}},\n",
       " {'run_tag': 'realunet_quick',\n",
       "  'type': 'model',\n",
       "  'model': 'real',\n",
       "  'train_folder': '/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/data/singlecoil_train',\n",
       "  'val_folder': '/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/data/singlecoil_val',\n",
       "  'mask': {'accel': 6, 'acs': 20},\n",
       "  'train_subset': 64,\n",
       "  'val_subset': 16,\n",
       "  'batch_size': 4,\n",
       "  'num_workers': 0,\n",
       "  'epochs': 1,\n",
       "  'learning_rate': 0.001,\n",
       "  'width_scale': 1.42,\n",
       "  'features': [16, 32, 64, 128, 256],\n",
       "  'seed': 1,\n",
       "  'qualitative_index': 0},\n",
       " {'run_tag': 'complexunet_quick',\n",
       "  'type': 'model',\n",
       "  'model': 'complex',\n",
       "  'train_folder': '/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/data/singlecoil_train',\n",
       "  'val_folder': '/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/data/singlecoil_val',\n",
       "  'mask': {'accel': 6, 'acs': 20},\n",
       "  'train_subset': 64,\n",
       "  'val_subset': 16,\n",
       "  'batch_size': 4,\n",
       "  'num_workers': 0,\n",
       "  'epochs': 1,\n",
       "  'learning_rate': 0.001,\n",
       "  'features': [16, 32, 64, 128, 256],\n",
       "  'seed': 1,\n",
       "  'qualitative_index': 0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS = [\n",
    "    {\n",
    "        'run_tag': 'zerofill_sweep',\n",
    "        'type': 'zero_fill',\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'val_subset': 64,\n",
    "        'grid_index': 50,\n",
    "        'mask_grid': {'accels': [2, 4, 6, 8], 'acs': [16, 20, 24]},\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'run_tag': 'realunet_R6_seed0',\n",
    "        'type': 'model',\n",
    "        'model': 'real',\n",
    "        'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'mask': {'accel': 6, 'acs': 20},\n",
    "        'train_subset': 16384,\n",
    "        'val_subset': 1024,\n",
    "        'batch_size': 4, \n",
    "        'num_workers': 4,\n",
    "        'epochs': 12,\n",
    "        'learning_rate': 1e-3,\n",
    "        'width_scale': 1.42,\n",
    "        'features': [16, 32, 64, 128, 256],\n",
    "        'seed': 0,\n",
    "        'qualitative_index': 50,\n",
    "    },\n",
    "    {\n",
    "        'run_tag': 'complexunet_R6_seed0',\n",
    "        'type': 'model',\n",
    "        'model': 'complex',\n",
    "        'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'mask': {'accel': 6, 'acs': 20},\n",
    "        'train_subset': 16384,\n",
    "        'val_subset': 1024,\n",
    "        'batch_size': 4,\n",
    "        'num_workers': 4,\n",
    "        'epochs': 12,\n",
    "        'learning_rate': 1e-3,\n",
    "        'features': [16, 32, 64, 128, 256],\n",
    "        'seed': 0,\n",
    "        'qualitative_index': 50,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Quick sanity runs (much smaller) to validate logging/IO without long training.\n",
    "QUICK_EXPERIMENTS = [\n",
    "    {\n",
    "        'run_tag': 'zerofill_quick',\n",
    "        'type': 'zero_fill',\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'val_subset': 4,\n",
    "        'grid_index': 0,\n",
    "        'mask_grid': {'accels': [6], 'acs': [20]},\n",
    "    },\n",
    "    {\n",
    "        'run_tag': 'realunet_quick',\n",
    "        'type': 'model',\n",
    "        'model': 'real',\n",
    "        'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'mask': {'accel': 6, 'acs': 20},\n",
    "        'train_subset': 64,\n",
    "        'val_subset': 16,\n",
    "        'batch_size': 4,\n",
    "        'num_workers': 0,\n",
    "        'epochs': 1,\n",
    "        'learning_rate': 1e-3,\n",
    "        'width_scale': 1.42,\n",
    "        'features': [16, 32, 64, 128, 256],\n",
    "        'seed': 1,\n",
    "        'qualitative_index': 0,\n",
    "    },\n",
    "    {\n",
    "        'run_tag': 'complexunet_quick',\n",
    "        'type': 'model',\n",
    "        'model': 'complex',\n",
    "        'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'mask': {'accel': 6, 'acs': 20},\n",
    "        'train_subset': 64,\n",
    "        'val_subset': 16,\n",
    "        'batch_size': 4,\n",
    "        'num_workers': 0,\n",
    "        'epochs': 1,\n",
    "        'learning_rate': 1e-3,\n",
    "        'features': [16, 32, 64, 128, 256],\n",
    "        'seed': 1,\n",
    "        'qualitative_index': 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "USE_QUICK = True  # set True for the fast sanity suite\n",
    "ACTIVE_EXPERIMENTS = QUICK_EXPERIMENTS if USE_QUICK else EXPERIMENTS\n",
    "ACTIVE_EXPERIMENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766a8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running zerofill_quick (zero_fill) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accel</th>\n",
       "      <th>acs</th>\n",
       "      <th>idx</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>16.455532</td>\n",
       "      <td>0.352846</td>\n",
       "      <td>0.115951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accel  acs  idx       psnr      ssim        l1\n",
       "0      6   20    0  16.455532  0.352846  0.115951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running realunet_quick (model) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0562979090604a52a719351d504e24b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c8590b53e04f62b42acb8e2ee39241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[realunet_quick] Epoch 1/1 | train 0.1579 | val 0.2060 | psnr 5.63 | ssim 0.005 | l1 0.4815\n",
      "=== Running complexunet_quick (model) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3345417aa3164d40bd28af49c312cc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df76b6a6c5e147da90b1b3bafc99f5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[complexunet_quick] Epoch 1/1 | train 0.3082 | val 0.1123 | psnr 4.52 | ssim 0.042 | l1 0.5895\n"
     ]
    }
   ],
   "source": [
    "for cfg in ACTIVE_EXPERIMENTS:\n",
    "    run_experiment(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1e8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece570",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
