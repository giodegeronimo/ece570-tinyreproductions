{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Runner — Automated Batch\n",
    "Runs zero-filled and real/complex U-Nets sequentially so overnight jobs log everything needed for the paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. Configure experiments in the cell below.\n",
    "2. Execute the final cell to iterate through each run.\n",
    "3. Inspect `results/` in the morning for metrics, checkpoints, and figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b630d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == 'notebooks':\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "SRC_ROOT = PROJECT_ROOT / 'src'\n",
    "RESULTS_ROOT = PROJECT_ROOT / 'results'\n",
    "RESULTS_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "import sys\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from data.dataset import SingleCoilDataset\n",
    "from data.masking import EquispacedMasker\n",
    "from models.real_unet import RealUnet\n",
    "from models.cx_unet import ComplexUnet\n",
    "from training.utils import train_loop, test_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d595f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_run(run_tag: str, config: dict) -> Path:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    run_dir = RESULTS_ROOT / f\"{timestamp}_{run_tag}\"\n",
    "    (run_dir / 'checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / 'qualitative').mkdir(exist_ok=True)\n",
    "    (run_dir / 'tensors').mkdir(exist_ok=True)\n",
    "    with open(run_dir / 'config.yaml', 'w') as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "    with open(run_dir / 'config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def to_mag(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.abs()\n",
    "\n",
    "\n",
    "def psnr_db(x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    mse = torch.mean((x - y) ** 2)\n",
    "    return 10.0 * torch.log10(1.0 / (mse + eps))\n",
    "\n",
    "\n",
    "def ssim_simple(x: torch.Tensor, y: torch.Tensor, C1: float = 0.01**2, C2: float = 0.03**2) -> torch.Tensor:\n",
    "    mu_x, mu_y = x.mean(), y.mean()\n",
    "    sigma_x = ((x - mu_x) ** 2).mean()\n",
    "    sigma_y = ((y - mu_y) ** 2).mean()\n",
    "    sigma_xy = ((x - mu_x) * (y - mu_y)).mean()\n",
    "    num = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    den = (mu_x**2 + mu_y**2 + C1) * (sigma_x + sigma_y + C2)\n",
    "    return num / (den + 1e-8)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_metrics(model, dataloader, device, num_batches: int = 2):\n",
    "    model.eval()\n",
    "    psnrs, ssim_scores = [], []\n",
    "    for batch_idx, (masked, target) in enumerate(dataloader):\n",
    "        masked = masked.to(device)\n",
    "        target = target.to(device)\n",
    "        recon = model(masked)\n",
    "        gt = to_mag(target)\n",
    "        pred = to_mag(recon)\n",
    "        gt = gt / gt.max().clamp_min(1e-8)\n",
    "        pred = pred / pred.max().clamp_min(1e-8)\n",
    "        psnrs.append(psnr_db(pred, gt).item())\n",
    "        ssim_scores.append(ssim_simple(pred, gt).item())\n",
    "        if (batch_idx + 1) >= num_batches:\n",
    "            break\n",
    "    return float(sum(psnrs) / max(len(psnrs), 1)), float(sum(ssim_scores) / max(len(ssim_scores), 1))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_qualitative(run_dir: Path, model, dataset, device, epoch: int, sample_idx: int | None = None):\n",
    "    model.eval()\n",
    "    if len(dataset) == 0:\n",
    "        return\n",
    "    idx = sample_idx if sample_idx is not None else (epoch * 11) % len(dataset)\n",
    "    masked, target = dataset[idx]\n",
    "    masked = masked.unsqueeze(0).to(device)\n",
    "    target = target.unsqueeze(0).to(device)\n",
    "    recon = model(masked)\n",
    "    gt = to_mag(target[0]).cpu()\n",
    "    pred = to_mag(recon[0]).cpu()\n",
    "    zf = to_mag(masked[0]).cpu()\n",
    "    for img in (gt, pred, zf):\n",
    "        img /= img.max().clamp_min(1e-8)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    for ax, img, title in zip(axes, [zf, pred, gt], ['Zero-filled', 'Model', 'Ground Truth']):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f'Epoch {epoch}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(run_dir / 'qualitative' / f'epoch{epoch:03d}.png', dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def select_indices(n_total: int, n_pick: int) -> np.ndarray:\n",
    "    n = min(n_total, n_pick)\n",
    "    if n_total == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    return np.linspace(0, n_total - 1, num=n, dtype=int)\n",
    "\n",
    "\n",
    "def save_zero_fill_grid(cfg: dict, run_dir: Path):\n",
    "    accels = cfg['mask_grid']['accels']\n",
    "    acs_list = cfg['mask_grid']['acs']\n",
    "    idx = cfg.get('grid_index', 0)\n",
    "    n_rows = len(accels)\n",
    "    n_cols = len(acs_list) + 1\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 3 * n_rows), squeeze=False)\n",
    "    for r_i, accel in enumerate(accels):\n",
    "        gt_shown = False\n",
    "        for a_i, acs in enumerate(acs_list):\n",
    "            ds = SingleCoilDataset(cfg['val_folder'], mask_func=EquispacedMasker(accel=accel, acs=acs))\n",
    "            slice_idx = min(idx, len(ds) - 1)\n",
    "            masked, target = ds[slice_idx]\n",
    "            gt = to_mag(target).cpu()\n",
    "            zf = to_mag(masked).cpu()\n",
    "            gt = gt / gt.max().clamp_min(1e-8)\n",
    "            zf = zf / zf.max().clamp_min(1e-8)\n",
    "            if not gt_shown:\n",
    "                ax_gt = axs[r_i, 0]\n",
    "                ax_gt.imshow(gt.squeeze(), cmap='gray')\n",
    "                ax_gt.set_title('Ground Truth', fontsize=8)\n",
    "                ax_gt.set_ylabel(f'R={accel}', fontsize=8)\n",
    "                ax_gt.axis('off')\n",
    "                gt_shown = True\n",
    "            ax = axs[r_i, a_i + 1]\n",
    "            ax.imshow(zf.squeeze(), cmap='gray')\n",
    "            ax.set_title(f'ACS={acs}', fontsize=8)\n",
    "            ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(run_dir / 'zero_fill_grid.png', dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def run_zero_fill_experiment(cfg: dict):\n",
    "    run_dir = init_run(cfg['run_tag'], cfg)\n",
    "    rows = []\n",
    "    accels = cfg['mask_grid']['accels']\n",
    "    acs_list = cfg['mask_grid']['acs']\n",
    "    slice_count = cfg.get('val_subset', 64)\n",
    "    for accel in accels:\n",
    "        for acs in acs_list:\n",
    "            ds = SingleCoilDataset(cfg['val_folder'], mask_func=EquispacedMasker(accel=accel, acs=acs))\n",
    "            idxs = select_indices(len(ds), slice_count)\n",
    "            psnrs, ssims, l1s = [], [], []\n",
    "            for idx in idxs:\n",
    "                masked, target = ds[idx]\n",
    "                gt = to_mag(target).float()\n",
    "                zf = to_mag(masked).float()\n",
    "                gt = gt / gt.max().clamp_min(1e-8)\n",
    "                zf = zf / zf.max().clamp_min(1e-8)\n",
    "                psnrs.append(psnr_db(zf, gt).item())\n",
    "                ssims.append(ssim_simple(zf, gt).item())\n",
    "                l1s.append(torch.mean(torch.abs(zf - gt)).item())\n",
    "            rows.append({\n",
    "                'accel': accel,\n",
    "                'acs': acs,\n",
    "                'N': len(idxs),\n",
    "                'PSNR_mean': float(np.mean(psnrs)) if psnrs else 0.0,\n",
    "                'PSNR_std': float(np.std(psnrs)) if psnrs else 0.0,\n",
    "                'SSIM_mean': float(np.mean(ssims)) if ssims else 0.0,\n",
    "                'SSIM_std': float(np.std(ssims)) if ssims else 0.0,\n",
    "                'L1_mean': float(np.mean(l1s)) if l1s else 0.0,\n",
    "                'L1_std': float(np.std(l1s)) if l1s else 0.0,\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(run_dir / 'zero_fill_metrics.csv', index=False)\n",
    "    display(df)\n",
    "    save_zero_fill_grid(cfg, run_dir)\n",
    "\n",
    "\n",
    "def build_subset(dataset, subset_size):\n",
    "    if subset_size is None:\n",
    "        return dataset\n",
    "    n = min(len(dataset), subset_size)\n",
    "    indices = list(range(n))\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "def run_model_experiment(cfg: dict):\n",
    "    torch.manual_seed(cfg.get('seed', 0))\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    run_dir = init_run(cfg['run_tag'], cfg)\n",
    "    mask_cfg = cfg.get('mask', {'accel': 4, 'acs': 24})\n",
    "    masker = EquispacedMasker(accel=mask_cfg['accel'], acs=mask_cfg['acs'])\n",
    "    train_full = SingleCoilDataset(cfg['train_folder'], mask_func=masker)\n",
    "    val_full = SingleCoilDataset(cfg['val_folder'], mask_func=masker)\n",
    "    train_set = build_subset(train_full, cfg.get('train_subset'))\n",
    "    val_set = build_subset(val_full, cfg.get('val_subset'))\n",
    "    train_loader = DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'])\n",
    "    val_loader = DataLoader(val_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'])\n",
    "    features = cfg.get('features', [32, 64, 128, 256, 512])\n",
    "    if cfg.get('model', 'real') == 'complex':\n",
    "        model = ComplexUnet(in_channels=1, out_channels=1, features=features).to(device)\n",
    "    else:\n",
    "        model = RealUnet(in_channels=1, out_channels=1, features=features, width_scale=cfg.get('width_scale', 1.0)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "    loss_fn = lambda pred, target: (pred - target).abs().mean()\n",
    "    metrics_path = run_dir / 'metrics.csv'\n",
    "    with metrics_path.open('w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['epoch', 'train_loss', 'val_loss', 'psnr', 'ssim'])\n",
    "        writer.writeheader()\n",
    "    best_val = float('inf')\n",
    "    summary_path = run_dir / 'metrics_summary.json'\n",
    "    qual_idx = cfg.get('qualitative_index', 0)\n",
    "    for epoch in range(1, cfg['epochs'] + 1):\n",
    "        train_loss = train_loop(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss = test_loop(model, val_loader, loss_fn, device)\n",
    "        psnr, ssim = evaluate_metrics(model, val_loader, device)\n",
    "        with metrics_path.open('a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['epoch', 'train_loss', 'val_loss', 'psnr', 'ssim'])\n",
    "            writer.writerow({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'psnr': psnr, 'ssim': ssim})\n",
    "        summary = {'best_val_loss': float(min(best_val, val_loss)), 'last_epoch': epoch, 'device': str(device)}\n",
    "        summary_path.write_text(json.dumps(summary, indent=2))\n",
    "        torch.save({'model': model.state_dict(), 'epoch': epoch}, run_dir / 'checkpoints' / 'latest.pt')\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save({'model': model.state_dict(), 'epoch': epoch}, run_dir / 'checkpoints' / 'best.pt')\n",
    "        save_qualitative(run_dir, model, val_set, device, epoch, sample_idx=qual_idx)\n",
    "        print(f\"[{cfg['run_tag']}] Epoch {epoch}/{cfg['epochs']} | train {train_loss:.4f} | val {val_loss:.4f} | psnr {psnr:.2f} | ssim {ssim:.3f}\")\n",
    "\n",
    "\n",
    "def run_experiment(cfg: dict):\n",
    "    exp_type = cfg['type']\n",
    "    print(f\"=== Running {cfg['run_tag']} ({exp_type}) ===\")\n",
    "    if exp_type == 'zero_fill':\n",
    "        run_zero_fill_experiment(cfg)\n",
    "    elif exp_type == 'model':\n",
    "        run_model_experiment(cfg)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown experiment type: {exp_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b194566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'run_tag': 'complexunet_R6_seed0',\n",
       "  'type': 'model',\n",
       "  'model': 'complex',\n",
       "  'train_folder': '/home/gdegeron/Desktop/ece570-tinyreproductions/data/singlecoil_train',\n",
       "  'val_folder': '/home/gdegeron/Desktop/ece570-tinyreproductions/data/singlecoil_val',\n",
       "  'mask': {'accel': 6, 'acs': 20},\n",
       "  'train_subset': 8192,\n",
       "  'val_subset': 1024,\n",
       "  'batch_size': 2,\n",
       "  'num_workers': 4,\n",
       "  'epochs': 1,\n",
       "  'learning_rate': 0.001,\n",
       "  'features': [16, 32, 64, 128, 256],\n",
       "  'seed': 0,\n",
       "  'qualitative_index': 50}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "EXPERIMENTS = [\n",
    "    # {\n",
    "    #     'run_tag': 'zerofill_sweep',\n",
    "    #     'type': 'zero_fill',\n",
    "    #     'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "    #     'val_subset': 64,\n",
    "    #     'grid_index': 50,\n",
    "    #     'mask_grid': {'accels': [2, 4, 6, 8], 'acs': [4, 12, 20]},\n",
    "    # },\n",
    "\n",
    "    # {\n",
    "    #     'run_tag': 'realunet_R6_seed0',\n",
    "    #     'type': 'model',\n",
    "    #     'model': 'real',\n",
    "    #     'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "    #     'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "    #     'mask': {'accel': 6, 'acs': 20},\n",
    "    #     'train_subset': 16384,\n",
    "    #     'val_subset': 1024,\n",
    "    #     'batch_size': 4, \n",
    "    #     'num_workers': 4,\n",
    "    #     'epochs': 1, # 6 * 16384 / 2 = 49152 steps\n",
    "    #     'learning_rate': 1e-3,\n",
    "    #     'width_scale': 1.42,\n",
    "    #     'features': [16, 32, 64, 128, 256],\n",
    "    #     'seed': 0,\n",
    "    #     'qualitative_index': 50,\n",
    "    # },\n",
    "    {\n",
    "        'run_tag': 'complexunet_R6_seed0',\n",
    "        'type': 'model',\n",
    "        'model': 'complex',\n",
    "        'train_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_train'),\n",
    "        'val_folder': str(PROJECT_ROOT / 'data' / 'singlecoil_val'),\n",
    "        'mask': {'accel': 6, 'acs': 20},\n",
    "        'train_subset': 8192,\n",
    "        'val_subset': 1024,\n",
    "        'batch_size': 2,\n",
    "        'num_workers': 4,\n",
    "        'epochs': 1,\n",
    "        'learning_rate': 1e-3,\n",
    "        'features': [16, 32, 64, 128, 256],\n",
    "        'seed': 0,\n",
    "        'qualitative_index': 50,\n",
    "    },\n",
    "]\n",
    "EXPERIMENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running complexunet_R6_seed0 (model) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  59%|█████▉    | 2437/4096 [12:56<08:48,  3.14it/s]"
     ]
    }
   ],
   "source": [
    "for cfg in EXPERIMENTS:\n",
    "    run_experiment(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1e8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
