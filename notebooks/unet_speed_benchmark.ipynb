{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Throughput Benchmark\n",
    "\n",
    "This notebook measures the training throughput (images/second) of the real and complex U-Nets as a function of batch size and model width. Synthetic inputs are used so the results isolate compute efficiency on the current hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == 'notebooks':\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "SRC_ROOT = PROJECT_ROOT / 'src'\n",
    "import sys\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from models.real_unet import RealUnet\n",
    "from models.cx_unet import ComplexUnet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Benchmark steps: 10, warmup: 5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZES = [1, 2, 4]\n",
    "FEATURE_CONFIGS = {\n",
    "    'tiny': [8, 16, 32, 64, 128],\n",
    "    #'base': [16, 32, 64, 128, 256],\n",
    "    #'large': [32, 64, 128, 256, 512],\n",
    "}\n",
    "BENCH_STEPS = 10  # iterations measured\n",
    "WARMUP_STEPS = 5\n",
    "INPUT_SHAPE = (1, 640, 320)  # (channels, H, W)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Benchmark steps: {BENCH_STEPS}, warmup: {WARMUP_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(kind: str, features: list[int]):\n",
    "    if kind == 'real':\n",
    "        return RealUnet(in_channels=1, out_channels=1, features=features, width_scale=1.0).to(DEVICE)\n",
    "    if kind == 'complex':\n",
    "        return ComplexUnet(in_channels=1, out_channels=1, features=features).to(DEVICE)\n",
    "    raise ValueError(f\"Unknown model kind: {kind}\")\n",
    "\n",
    "\n",
    "def make_batch(batch_size: int):\n",
    "    shape = (batch_size, *INPUT_SHAPE)\n",
    "    real = torch.randn(shape, dtype=torch.float32, device=DEVICE)\n",
    "    imag = torch.randn(shape, dtype=torch.float32, device=DEVICE)\n",
    "    batch = torch.complex(real, imag)\n",
    "    return batch\n",
    "\n",
    "\n",
    "def benchmark_step(model, optimizer, batch_size: int):\n",
    "    inputs = make_batch(batch_size)\n",
    "    targets = make_batch(batch_size)\n",
    "    # simple L1 loss to match training behavior\n",
    "    criterion = lambda pred, tgt: torch.mean(torch.abs(pred - tgt))\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(WARMUP_STEPS):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize() if DEVICE.type == 'cuda' else None\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(BENCH_STEPS):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.cuda.synchronize() if DEVICE.type == 'cuda' else None\n",
    "    elapsed = time.perf_counter() - start\n",
    "    images = batch_size * BENCH_STEPS\n",
    "    return images / elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking real | config tiny\n",
      "Benchmarking complex | config tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ece570/lib/python3.12/site-packages/torch/nn/modules/module.py:1341: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.\n",
      "  warnings.warn(\n",
      "/Users/giodegeronimo/Desktop/ECE570/ece570-tinyreproductions/src/models/cx_unet.py:143: UserWarning: The operator 'aten::_linalg_eigh.eigenvalues' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:15.)\n",
      "  eigvals, eigvecs = torch.linalg.eigh(V)  # (C, 2), (C, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>config</th>\n",
       "      <th>features</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>images_per_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>1</td>\n",
       "      <td>34.318817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>2</td>\n",
       "      <td>64.119999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>4</td>\n",
       "      <td>89.939659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complex</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.008742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complex</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.040376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>complex</td>\n",
       "      <td>tiny</td>\n",
       "      <td>[8, 16, 32, 64, 128]</td>\n",
       "      <td>4</td>\n",
       "      <td>1.076109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model config              features  batch_size  images_per_sec\n",
       "0     real   tiny  [8, 16, 32, 64, 128]           1       34.318817\n",
       "1     real   tiny  [8, 16, 32, 64, 128]           2       64.119999\n",
       "2     real   tiny  [8, 16, 32, 64, 128]           4       89.939659\n",
       "3  complex   tiny  [8, 16, 32, 64, 128]           1        1.008742\n",
       "4  complex   tiny  [8, 16, 32, 64, 128]           2        1.040376\n",
       "5  complex   tiny  [8, 16, 32, 64, 128]           4        1.076109"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for model_kind, config_name in itertools.product(['real', 'complex'], FEATURE_CONFIGS.keys()):\n",
    "    features = FEATURE_CONFIGS[config_name]\n",
    "    print(f\"Benchmarking {model_kind} | config {config_name}\")\n",
    "    model = make_model(model_kind, features)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        try:\n",
    "            imgs_per_sec = benchmark_step(model, optimizer, batch_size)\n",
    "        except RuntimeError as err:\n",
    "            imgs_per_sec = float('nan')\n",
    "            print(f\"  batch {batch_size} OOM/error: {err}\")\n",
    "        results.append({\n",
    "            'model': model_kind,\n",
    "            'config': config_name,\n",
    "            'features': features,\n",
    "            'batch_size': batch_size,\n",
    "            'images_per_sec': imgs_per_sec,\n",
    "        })\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache() if DEVICE.type == 'cuda' else None\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>config</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <th>tiny</th>\n",
       "      <td>1.008742</td>\n",
       "      <td>1.040376</td>\n",
       "      <td>1.076109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th>tiny</th>\n",
       "      <td>34.318817</td>\n",
       "      <td>64.119999</td>\n",
       "      <td>89.939659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "batch_size              1          2          4\n",
       "model   config                                 \n",
       "complex tiny     1.008742   1.040376   1.076109\n",
       "real    tiny    34.318817  64.119999  89.939659"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index=['model', 'config'], columns='batch_size', values='images_per_sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7e393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece570",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
